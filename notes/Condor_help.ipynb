{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b55d9b-1ec7-4adc-b2c0-b092e90a6b14",
   "metadata": {},
   "source": [
    "# Condor Submit Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d734b-7ab5-469b-9f34-5cc7de79f3c8",
   "metadata": {},
   "source": [
    "First step is to run the script `condor_submit_nano_connect_ntuples.py`, give this script a `.list` file as one of the inputs, for example:\n",
    "\n",
    "`[dgrove@login SUSYCascades]$ python3 scripts/condor_submit_nano_connect_ntuples.py -list samples/NANO/Lists/SUSYCascade_Sample.list -split 20 --verbose --dry-run`\n",
    "\n",
    "# IF RUNNING OVER SIGNAL:\n",
    "\n",
    "`[dgrove@login SUSYCascades]$ python3 scripts/condor_submit_nano_connect_ntuples.py -list samples/NANO/Lists/SUSYCascade_Sample.list -split 20 --verbose --dry-run --sms`\n",
    "\n",
    "\n",
    "**Note:** This is run from the SUSYCascades directory\n",
    "\n",
    "output the `.list` file to see what it looks like:\n",
    "\n",
    "```\n",
    "[dgrove@login SUSYCascades]$ cat samples/NANO/Lists/Summer23_130X.list\n",
    "samples/NANO/Summer23_130X/TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35e79f-cbd8-42b3-969a-1c4e48aa359e",
   "metadata": {},
   "source": [
    "Lets go into the `.txt` now and see whats in there:\n",
    "\n",
    "\n",
    "`[dgrove@login SUSYCascades]$ cat samples/NANO/Summer23_130X/TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8.txt`\n",
    "```\n",
    "root://cmsxrootd.fnal.gov//store/mc/Run3Summer23NanoAODv12/TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8/NANOAODSIM/130X_mcRun3_2023_realistic_v14-v2/70000/428c6754-4ad2-4c2f-8ec6-4f2b5dc60758.root\n",
    "root://cmsxrootd.fnal.gov//store/mc/Run3Summer23NanoAODv12/TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8/NANOAODSIM/130X_mcRun3_2023_realistic_v14-v2/70000/d48cf12d-e6f4-4c59-ba57-126ee52c18a0.root\n",
    "...\n",
    "```\n",
    "\n",
    "... implies many many more redirectors to different root files. These are all the root files in a given MC data sample, seen [here](https://cmsweb.cern.ch/das/request?instance=prod/global&input=file+dataset%3D%2FTTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8%2FRun3Summer23NanoAODv12-130X_mcRun3_2023_realistic_v14-v2%2FNANOAODSIM)\n",
    "\n",
    "So, lets recap, we need a `.txt` file which is full of all the redirector links to the root files we want to run over. Next, we need a `.list` file that simply paths to the location of that `.txt` file (a `.list` file can have multiple paths on separate lines so we can have many `.txt` file inputs (which would correspond to multiple MC data samples for background or signal or whatever) into a single condor submit script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fe7ee-8609-4330-88fa-fc9f46b2ea1c",
   "metadata": {},
   "source": [
    "Now then, the output of the `condor_submit_nano_connect_ntuples.py` script is a directory that contains the relevant files and logs to submit to condor. To submit to condor we run:\n",
    "\n",
    "`condor_submit` and as an input we give it the location of the `.submit` file generated from the python script, full command example would be this:\n",
    "\n",
    "`condor_submit Summer23_130X/src/TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8_Summer23_130X_single.submit`\n",
    "\n",
    "here there would be two `.submit` files at that location, \n",
    "\n",
    "`TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8_Summer23_130X_single.submit`\n",
    "\n",
    "and\n",
    "\n",
    "`TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8_Summer23_130X.submit`\n",
    "\n",
    "the difference being, `~_single.submit` is meant to submitted first as a test to see if what comes back from condor looks correct. If that comes back ok then it should be fine to submit the full job, `TTto2L2Nu_TuneCP5_13p6TeV_powheg-pythia8_Summer23_130X.submit`\n",
    "\n",
    "Once the job is submitted to condor we can keep tabs with \n",
    "\n",
    "`watch condor_q $USER -batch`\n",
    "\n",
    "The output files should be in a subdirectory in the `/ospool/cms-user/dgrove/NTUPLES/` area\n",
    "\n",
    "I've been working in this directory:\n",
    "`/eos/home-d/dgrove/datasets` on lxplus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a686161-5ad0-42f1-9bdb-950bafba21a5",
   "metadata": {},
   "source": [
    "## Nuance (understand this before trying to make `.submit` files)\n",
    "\n",
    "the condor submit python file has a list named `knowntags` that it needs to have an entry for the `.list` file in order to find said list file, I think its for the list file at least. \n",
    "\n",
    "\n",
    "Caleb in Slack: \"A common problem is getting held jobs for a number of CPU issue… I have examples in my text files, but I will include this if I make instructions…\"\n",
    "\n",
    "`condor_q -held`\n",
    "\n",
    "```\n",
    "-- Schedd: login-el7.uscms.org : <192.170.231.212:9618?... @ 04/18/24 10:45:37\n",
    " ID          OWNER          HELD_SINCE  HOLD_REASON\n",
    "17067736.446 caleb           4/18 10:43 The number of CPU load exceeds the number of requested CPUs. Please, check your workflow c\n",
    "pu/core requirements.        \n",
    "17067736.455 caleb           4/18 10:44 The number of CPU load exceeds the number of requested CPUs. Please, check your workflow cpu/core requirements.        \n",
    "17067736.456 caleb           4/18 10:43 The number of CPU load exceeds the number of requested CPUs. Please, check your workflow cpu/core requirements.\n",
    "```\n",
    "\n",
    "For this problem, we do these two commands, which Zach provided:\n",
    "\n",
    "`condor_qedit $USER RequestCpus=4`\n",
    "```\n",
    "Set attribute \"RequestCpus\" for 154 matching jobs.\n",
    "````\n",
    "\n",
    "`condor_release -all`\n",
    "```\n",
    "All jobs have been released\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39148675-bfde-4114-acc2-7edc80103f5a",
   "metadata": {},
   "source": [
    "## Generating text files conveniently:\n",
    "\n",
    "From Caleb, do these commands to generate the text files that we need for our condor job (.list file is still manually created however its just a directory pointer to this text file). You will need grid certificates and proxy enabled for this to work:\n",
    "\n",
    "`dasgoclient -query=\"dataset=/TTJets_DiLept_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer20UL17NanoAODv9-106X_mc2017_realistic_v9-v1/NANOAODSIM\"`\n",
    "\n",
    "That queries the server for the data set?\n",
    "\n",
    "`dasgoclient -query=\"file dataset=/TTJets_DiLept_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer20UL17NanoAODv9-106X_mc2017_realistic_v9-v1/NANOAODSIM\"`\n",
    "\n",
    "The above does almost the same but it prints out all the files for that data set. Can you guess the next step? Pipe it into a .txt file:\n",
    "\n",
    "`dasgoclient -query=\"file dataset=/TTJets_DiLept_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer20UL17NanoAODv9-106X_mc2017_realistic_v9-v1/NANOAODSIM\" > TTJets_DiLept_TuneCP5_13TeV-madgraphMLM-pythia8_UL2017_NanoAODv9.txt`\n",
    "\n",
    "We are missing one final step, we need to append to the beginning of each line the text for our redirector, so run this:\n",
    "\n",
    "`sed -i 's/^/root:\\/\\/cms-xrd-global.cern.ch\\//' TTJets_DiLept_TuneCP5_13TeV-madgraphMLM-pythia8_UL2017_NanoAODv9.txt`\n",
    "\n",
    "Kepe in mind you need to change the text file name for something more appropriate relative to the dataset you're printing, then you also need to use that same text file name in the last command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5997f42-c773-4684-a7be-cc549717f296",
   "metadata": {},
   "source": [
    "For checking *used* storage space on cms connect:\n",
    "\n",
    "```\n",
    "alias check_home='du -sh /home/$USER'\n",
    "\n",
    "alias check_ospool='du -sh /ospool/cms-user/$USER'\n",
    "\n",
    "alias check_scratch='du -sh /local-scratch/$USER'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba4d8a-89aa-4607-a02c-9449fe5ab0fb",
   "metadata": {},
   "source": [
    "Useful commands for editing condor jobs after: \n",
    "\n",
    "`condor_qedit`\n",
    "\n",
    "`condor_qedit $USER RequestMemory=1000`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb9c7d-c536-462b-a73f-8489c5768a6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f49eebc8-8399-45e5-a70e-1078ec7440e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e675aeca-2fff-4307-99ac-291bdd95db95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b36eda6-6296-423e-b9ce-3b22037c35cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1480739a-2eb1-4a65-b8b5-8b51e224848a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a478a3a7-a0d4-499a-9f39-3342245f29a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
